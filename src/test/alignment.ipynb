{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd555b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Linguistic Alignment Metrics for Child-Adult Conversational Analysis\n",
    "\n",
    "Computes three types of alignment between child and adult turns:\n",
    "1. Lexical alignment: Overlap of lemmatized words\n",
    "2. Syntactic alignment: Overlap of POS tag sequences\n",
    "3. Semantic alignment: Cosine similarity of embeddings\n",
    "\n",
    "All metrics return normalized scores in [0, 1]\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c3d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LexicalAlignmentCalculator:\n",
    "    \"\"\"\n",
    "    Computes lexical alignment based on lemma overlap rate.\n",
    "    \n",
    "    Alignment = |lemmas_child ∩ lemmas_adult| / (|lemmas_child| + |lemmas_adult|)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"en_core_web_sm\", \n",
    "                 exclude_stopwords: bool = True,\n",
    "                 exclude_punctuation: bool = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: spaCy model to use\n",
    "            exclude_stopwords: Whether to exclude stopwords from alignment\n",
    "            exclude_punctuation: Whether to exclude punctuation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.nlp = spacy.load(model_name)\n",
    "        except OSError:\n",
    "            print(f\"Downloading spaCy model {model_name}...\")\n",
    "            import subprocess\n",
    "            subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", model_name])\n",
    "            self.nlp = spacy.load(model_name)\n",
    "        \n",
    "        self.exclude_stopwords = exclude_stopwords\n",
    "        self.exclude_punctuation = exclude_punctuation\n",
    "    \n",
    "    def _get_lemmas(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract lemmatized tokens from text.\"\"\"\n",
    "        doc = self.nlp(text.lower())\n",
    "        lemmas = []\n",
    "        \n",
    "        for token in doc:\n",
    "            # Filter based on settings\n",
    "            if self.exclude_punctuation and token.is_punct:\n",
    "                continue\n",
    "            if self.exclude_stopwords and token.is_stop:\n",
    "                continue\n",
    "            \n",
    "            lemmas.append(token.lemma_)\n",
    "        \n",
    "        return lemmas\n",
    "    \n",
    "    def compute_alignment(self, child_turn: str, adult_turn: str) -> float:\n",
    "        \"\"\"\n",
    "        Compute lexical alignment between child and adult turns.\n",
    "        \n",
    "        Args:\n",
    "            child_turn: Child's utterance\n",
    "            adult_turn: Adult's utterance\n",
    "            \n",
    "        Returns:\n",
    "            Alignment score in [0, 1]\n",
    "        \"\"\"\n",
    "        child_lemmas = self._get_lemmas(child_turn)\n",
    "        adult_lemmas = self._get_lemmas(adult_turn)\n",
    "        \n",
    "        # Handle empty cases\n",
    "        if len(child_lemmas) == 0 and len(adult_lemmas) == 0:\n",
    "            return 1.0  # Both empty = perfect alignment\n",
    "        if len(child_lemmas) == 0 or len(adult_lemmas) == 0:\n",
    "            return 0.0  # One empty = no alignment\n",
    "        \n",
    "        # Overlap rate: intersection / total\n",
    "        child_set = set(child_lemmas)\n",
    "        adult_set = set(adult_lemmas)\n",
    "        \n",
    "        intersection = len(child_set & adult_set)\n",
    "        total = len(child_lemmas) + len(adult_lemmas)\n",
    "        \n",
    "        alignment = intersection / total if total > 0 else 0.0\n",
    "        \n",
    "        return float(alignment)\n",
    "    \n",
    "    def compute_alignment_detailed(self, child_turn: str, adult_turn: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Compute alignment with detailed breakdown.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with alignment score and shared lemmas\n",
    "        \"\"\"\n",
    "        child_lemmas = self._get_lemmas(child_turn)\n",
    "        adult_lemmas = self._get_lemmas(adult_turn)\n",
    "        \n",
    "        child_set = set(child_lemmas)\n",
    "        adult_set = set(adult_lemmas)\n",
    "        shared_lemmas = child_set & adult_set\n",
    "        \n",
    "        alignment = self.compute_alignment(child_turn, adult_turn)\n",
    "        \n",
    "        return {\n",
    "            'alignment': alignment,\n",
    "            'child_lemmas': child_lemmas,\n",
    "            'adult_lemmas': adult_lemmas,\n",
    "            'shared_lemmas': list(shared_lemmas),\n",
    "            'num_child_lemmas': len(child_lemmas),\n",
    "            'num_adult_lemmas': len(adult_lemmas),\n",
    "            'num_shared': len(shared_lemmas),\n",
    "        }\n",
    "\n",
    "\n",
    "class SyntacticAlignmentCalculator:\n",
    "    \"\"\"\n",
    "    Computes syntactic alignment based on POS tag bigram overlap rate.\n",
    "    \n",
    "    Uses POS bigrams to capture sequential syntactic structure.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"en_core_web_sm\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: spaCy model to use\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.nlp = spacy.load(model_name)\n",
    "        except OSError:\n",
    "            print(f\"Downloading spaCy model {model_name}...\")\n",
    "            import subprocess\n",
    "            subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", model_name])\n",
    "            self.nlp = spacy.load(model_name)\n",
    "    \n",
    "    def _get_pos_tags(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract POS tags from text.\"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        # Use universal POS tags (coarse-grained)\n",
    "        pos_tags = [token.pos_ for token in doc if not token.is_punct]\n",
    "        return pos_tags\n",
    "    \n",
    "    def _get_pos_bigrams(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract POS tag bigrams to capture sequential structure.\"\"\"\n",
    "        pos_tags = self._get_pos_tags(text)\n",
    "        \n",
    "        if len(pos_tags) < 2:\n",
    "            return []\n",
    "        \n",
    "        # Create bigrams: \"DET_NOUN\", \"NOUN_VERB\", etc.\n",
    "        bigrams = [f\"{pos_tags[i]}_{pos_tags[i+1]}\" for i in range(len(pos_tags) - 1)]\n",
    "        return bigrams\n",
    "    \n",
    "    def compute_alignment(self, child_turn: str, adult_turn: str) -> float:\n",
    "        \"\"\"\n",
    "        Compute syntactic alignment between child and adult turns using POS bigrams.\n",
    "        \n",
    "        Args:\n",
    "            child_turn: Child's utterance\n",
    "            adult_turn: Adult's utterance\n",
    "            \n",
    "        Returns:\n",
    "            Alignment score in [0, 1]\n",
    "        \"\"\"\n",
    "        child_bigrams = self._get_pos_bigrams(child_turn)\n",
    "        adult_bigrams = self._get_pos_bigrams(adult_turn)\n",
    "        \n",
    "        # Handle empty cases\n",
    "        if len(child_bigrams) == 0 and len(adult_bigrams) == 0:\n",
    "            return 1.0  # Both empty = perfect alignment\n",
    "        if len(child_bigrams) == 0 or len(adult_bigrams) == 0:\n",
    "            return 0.0  # One empty = no alignment\n",
    "        \n",
    "        # Overlap rate: intersection / total\n",
    "        child_set = set(child_bigrams)\n",
    "        adult_set = set(adult_bigrams)\n",
    "        \n",
    "        intersection = len(child_set & adult_set)\n",
    "        total = len(child_bigrams) + len(adult_bigrams)\n",
    "        \n",
    "        alignment = intersection / total if total > 0 else 0.0\n",
    "        \n",
    "        return float(alignment)\n",
    "    \n",
    "    def compute_alignment_detailed(self, child_turn: str, adult_turn: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Compute alignment with detailed breakdown.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with alignment scores and POS tag information\n",
    "        \"\"\"\n",
    "        child_tags = self._get_pos_tags(child_turn)\n",
    "        adult_tags = self._get_pos_tags(adult_turn)\n",
    "        \n",
    "        child_bigrams = self._get_pos_bigrams(child_turn)\n",
    "        adult_bigrams = self._get_pos_bigrams(adult_turn)\n",
    "        \n",
    "        child_bigram_set = set(child_bigrams)\n",
    "        adult_bigram_set = set(adult_bigrams)\n",
    "        shared_bigrams = child_bigram_set & adult_bigram_set\n",
    "        \n",
    "        alignment = self.compute_alignment(child_turn, adult_turn)\n",
    "        \n",
    "        return {\n",
    "            'alignment': alignment,\n",
    "            'child_pos_tags': child_tags,\n",
    "            'adult_pos_tags': adult_tags,\n",
    "            'child_pos_bigrams': child_bigrams,\n",
    "            'adult_pos_bigrams': adult_bigrams,\n",
    "            'shared_bigrams': list(shared_bigrams),\n",
    "            'num_child_bigrams': len(child_bigrams),\n",
    "            'num_adult_bigrams': len(adult_bigrams),\n",
    "            'num_shared_bigrams': len(shared_bigrams),\n",
    "        }\n",
    "\n",
    "\n",
    "class SemanticAlignmentCalculator:\n",
    "    \"\"\"\n",
    "    Computes semantic alignment using sentence embeddings.\n",
    "    \n",
    "    Alignment = cosine_similarity(embedding_child, embedding_adult)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: SentenceTransformer model to use\n",
    "                       Options:\n",
    "                       - \"all-MiniLM-L6-v2\" (fast, 384 dim)\n",
    "                       - \"all-mpnet-base-v2\" (better quality, 768 dim)\n",
    "                       - \"paraphrase-MiniLM-L6-v2\" (paraphrase detection)\n",
    "        \"\"\"\n",
    "        print(f\"Loading semantic model: {model_name}...\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.model_name = model_name\n",
    "    \n",
    "    def _get_embedding(self, text: str) -> np.ndarray:\n",
    "        \"\"\"Get sentence embedding for text.\"\"\"\n",
    "        embedding = self.model.encode(text, convert_to_numpy=True)\n",
    "        return embedding\n",
    "    \n",
    "    def compute_alignment(self, child_turn: str, adult_turn: str) -> float:\n",
    "        \"\"\"\n",
    "        Compute semantic alignment between child and adult turns.\n",
    "        \n",
    "        Args:\n",
    "            child_turn: Child's utterance\n",
    "            adult_turn: Adult's utterance\n",
    "            \n",
    "        Returns:\n",
    "            Alignment score in [0, 1]\n",
    "            \n",
    "        Note:\n",
    "            Cosine similarity ranges from [-1, 1], but in practice\n",
    "            sentence embeddings rarely give negative values.\n",
    "            We clip to [0, 1] for consistency.\n",
    "        \"\"\"\n",
    "        # Handle empty inputs\n",
    "        if not child_turn.strip() or not adult_turn.strip():\n",
    "            return 0.0\n",
    "        \n",
    "        child_emb = self._get_embedding(child_turn)\n",
    "        adult_emb = self._get_embedding(adult_turn)\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        similarity = cosine_similarity(\n",
    "            child_emb.reshape(1, -1),\n",
    "            adult_emb.reshape(1, -1)\n",
    "        )[0, 0]\n",
    "        \n",
    "        # Clip to [0, 1] range\n",
    "        # (cosine similarity is theoretically [-1, 1], but usually positive)\n",
    "        alignment = np.clip(similarity, 0, 1)\n",
    "        \n",
    "        return float(alignment)\n",
    "    \n",
    "    def compute_alignment_batch(self, child_turns: List[str], \n",
    "                                adult_turns: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute semantic alignment for multiple turn pairs efficiently.\n",
    "        \n",
    "        Args:\n",
    "            child_turns: List of child utterances\n",
    "            adult_turns: List of adult utterances\n",
    "            \n",
    "        Returns:\n",
    "            Array of alignment scores\n",
    "        \"\"\"\n",
    "        if len(child_turns) != len(adult_turns):\n",
    "            raise ValueError(\"Number of child and adult turns must match\")\n",
    "        \n",
    "        # Batch encode for efficiency\n",
    "        child_embs = self.model.encode(child_turns, convert_to_numpy=True)\n",
    "        adult_embs = self.model.encode(adult_turns, convert_to_numpy=True)\n",
    "        \n",
    "        # Compute pairwise cosine similarities\n",
    "        alignments = []\n",
    "        for child_emb, adult_emb in zip(child_embs, adult_embs):\n",
    "            similarity = cosine_similarity(\n",
    "                child_emb.reshape(1, -1),\n",
    "                adult_emb.reshape(1, -1)\n",
    "            )[0, 0]\n",
    "            alignments.append(np.clip(similarity, 0, 1))\n",
    "        \n",
    "        return np.array(alignments)\n",
    "    \n",
    "    def compute_alignment_detailed(self, child_turn: str, adult_turn: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Compute alignment with embedding details.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with alignment score and embeddings\n",
    "        \"\"\"\n",
    "        child_emb = self._get_embedding(child_turn)\n",
    "        adult_emb = self._get_embedding(adult_turn)\n",
    "        \n",
    "        alignment = self.compute_alignment(child_turn, adult_turn)\n",
    "        \n",
    "        return {\n",
    "            'alignment': alignment,\n",
    "            'child_embedding': child_emb,\n",
    "            'adult_embedding': adult_emb,\n",
    "            'embedding_dim': len(child_emb),\n",
    "            'model_name': self.model_name,\n",
    "        }\n",
    "\n",
    "\n",
    "class LinguisticAlignmentSuite:\n",
    "    \"\"\"\n",
    "    Unified interface for computing all alignment metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 spacy_model: str = \"en_core_web_sm\",\n",
    "                 semantic_model: str = \"all-MiniLM-L6-v2\",\n",
    "                 exclude_stopwords: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize all alignment calculators.\n",
    "        \n",
    "        Args:\n",
    "            spacy_model: Model for lexical and syntactic alignment\n",
    "            semantic_model: Model for semantic alignment\n",
    "            exclude_stopwords: Whether to exclude stopwords in lexical alignment\n",
    "        \"\"\"\n",
    "        print(\"Initializing Linguistic Alignment Suite...\")\n",
    "        \n",
    "        self.lexical_calc = LexicalAlignmentCalculator(\n",
    "            model_name=spacy_model,\n",
    "            exclude_stopwords=exclude_stopwords\n",
    "        )\n",
    "        \n",
    "        self.syntactic_calc = SyntacticAlignmentCalculator(\n",
    "            model_name=spacy_model\n",
    "        )\n",
    "        \n",
    "        self.semantic_calc = SemanticAlignmentCalculator(\n",
    "            model_name=semantic_model\n",
    "        )\n",
    "        \n",
    "        print(\"✓ Alignment suite ready!\")\n",
    "    \n",
    "    def compute_all_alignments(self, child_turn: str, adult_turn: str) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Compute all three alignment types.\n",
    "        \n",
    "        Args:\n",
    "            child_turn: Child's utterance\n",
    "            adult_turn: Adult's utterance\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with all alignment scores (all in [0, 1])\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'lexical_alignment': self.lexical_calc.compute_alignment(child_turn, adult_turn),\n",
    "            'syntactic_alignment': self.syntactic_calc.compute_alignment(child_turn, adult_turn),\n",
    "            'semantic_alignment': self.semantic_calc.compute_alignment(child_turn, adult_turn),\n",
    "        }\n",
    "    \n",
    "    def compute_all_alignments_detailed(self, child_turn: str, adult_turn: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Compute all alignments with detailed breakdowns.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with detailed information for each alignment type\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'lexical': self.lexical_calc.compute_alignment_detailed(child_turn, adult_turn),\n",
    "            'syntactic': self.syntactic_calc.compute_alignment_detailed(child_turn, adult_turn),\n",
    "            'semantic': self.semantic_calc.compute_alignment_detailed(child_turn, adult_turn),\n",
    "        }\n",
    "    \n",
    "    def compute_batch(self, child_turns: List[str], adult_turns: List[str]) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Efficiently compute alignments for multiple turn pairs.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary of arrays with alignment scores\n",
    "        \"\"\"\n",
    "        n = len(child_turns)\n",
    "        if n != len(adult_turns):\n",
    "            raise ValueError(\"Number of child and adult turns must match\")\n",
    "        \n",
    "        # Lexical and syntactic need to be computed individually\n",
    "        lexical_scores = np.array([\n",
    "            self.lexical_calc.compute_alignment(c, a) \n",
    "            for c, a in zip(child_turns, adult_turns)\n",
    "        ])\n",
    "        \n",
    "        syntactic_scores = np.array([\n",
    "            self.syntactic_calc.compute_alignment(c, a)\n",
    "            for c, a in zip(child_turns, adult_turns)\n",
    "        ])\n",
    "        \n",
    "        # Semantic can be batched efficiently\n",
    "        semantic_scores = self.semantic_calc.compute_alignment_batch(\n",
    "            child_turns, adult_turns\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'lexical_alignment': lexical_scores,\n",
    "            'syntactic_alignment': syntactic_scores,\n",
    "            'semantic_alignment': semantic_scores,\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c59887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXAMPLE 1: Individual Calculators\n",
      "======================================================================\n",
      "\n",
      "--- Lexical Alignment (Overlap Rate) ---\n",
      "\n",
      "Child: night night.\n",
      "Adult: night night.\n",
      "Lexical alignment: 0.250\n",
      "\n",
      "Child: night night.\n",
      "Adult: night night!\n",
      "Lexical alignment: 0.250\n",
      "\n",
      "Child: my chicken.\n",
      "Adult: yeah chicken.\n",
      "Lexical alignment: 0.333\n",
      "\n",
      "Child: all done.\n",
      "Adult: all done okay.\n",
      "Lexical alignment: 0.000\n",
      "\n",
      "Detailed breakdown:\n",
      "  Shared lemmas: ['night']\n",
      "  Child lemmas: ['night', 'night']\n",
      "  Adult lemmas: ['night', 'night']\n",
      "  Overlap: 1 / (2 + 2) = 0.250\n",
      "\n",
      "======================================================================\n",
      "--- Syntactic Alignment (POS Bigrams) ---\n",
      "\n",
      "Child: night night.\n",
      "Adult: night night.\n",
      "Syntactic alignment: 0.500\n",
      "\n",
      "Child: night night.\n",
      "Adult: night night!\n",
      "Syntactic alignment: 0.500\n",
      "\n",
      "Child: my chicken.\n",
      "Adult: yeah chicken.\n",
      "Syntactic alignment: 0.000\n",
      "\n",
      "Child: all done.\n",
      "Adult: all done okay.\n",
      "Syntactic alignment: 0.333\n",
      "\n",
      "Detailed breakdown:\n",
      "  Child POS tags: ['NOUN', 'NOUN']\n",
      "  Adult POS tags: ['NOUN', 'NOUN']\n",
      "  Child POS bigrams: ['NOUN_NOUN']\n",
      "  Adult POS bigrams: ['NOUN_NOUN']\n",
      "  Shared bigrams: ['NOUN_NOUN']\n",
      "  Overlap: 1 / (1 + 1) = 0.500\n",
      "\n",
      "======================================================================\n",
      "--- Semantic Alignment ---\n",
      "Loading semantic model: all-MiniLM-L6-v2...\n",
      "\n",
      "Child: night night.\n",
      "Adult: night night.\n",
      "Semantic alignment: 1.000\n",
      "\n",
      "Child: night night.\n",
      "Adult: night night!\n",
      "Semantic alignment: 0.897\n",
      "\n",
      "Child: my chicken.\n",
      "Adult: yeah chicken.\n",
      "Semantic alignment: 0.599\n",
      "\n",
      "Child: all done.\n",
      "Adult: all done okay.\n",
      "Semantic alignment: 0.866\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE 2: Unified Alignment Suite\n",
      "======================================================================\n",
      "Initializing Linguistic Alignment Suite...\n",
      "Loading semantic model: all-MiniLM-L6-v2...\n",
      "✓ Alignment suite ready!\n",
      "\n",
      "Child: night night.\n",
      "Adult: night night.\n",
      "  Lexical:   0.250\n",
      "  Syntactic: 0.500\n",
      "  Semantic:  1.000\n",
      "\n",
      "Child: night night.\n",
      "Adult: night night!\n",
      "  Lexical:   0.250\n",
      "  Syntactic: 0.500\n",
      "  Semantic:  0.897\n",
      "\n",
      "Child: my chicken.\n",
      "Adult: yeah chicken.\n",
      "  Lexical:   0.333\n",
      "  Syntactic: 0.000\n",
      "  Semantic:  0.599\n",
      "\n",
      "Child: all done.\n",
      "Adult: all done okay.\n",
      "  Lexical:   0.000\n",
      "  Syntactic: 0.333\n",
      "  Semantic:  0.866\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE 3: Batch Processing\n",
      "======================================================================\n",
      "\n",
      "Batch results:\n",
      "Lexical alignments:   [0.25       0.25       0.33333333 0.        ]\n",
      "Syntactic alignments: [0.5        0.5        0.         0.33333333]\n",
      "Semantic alignments:  [0.99999994 0.89651966 0.59945476 0.86581266]\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE 4: Comprehensive Detailed Analysis\n",
      "======================================================================\n",
      "\n",
      "Child: night night.\n",
      "Adult: night night.\n",
      "\n",
      "Lexical alignment: 0.250\n",
      "  Shared lemmas: ['night']\n",
      "\n",
      "Syntactic alignment: 0.500\n",
      "  Shared POS bigrams: ['NOUN_NOUN']\n",
      "\n",
      "Semantic alignment: 1.000\n",
      "  Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# USAGE EXAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Example child-adult conversation pairs\n",
    "    examples = [\n",
    "        {\n",
    "            'child': \"night night.\",\n",
    "            'adult': \"night night.\",\n",
    "        },\n",
    "        {\n",
    "            'child': \"night night.\",\n",
    "            'adult': \"night night!\",\n",
    "        },\n",
    "        {\n",
    "            'child': \"my chicken.\",\n",
    "            'adult': \"yeah chicken.\",\n",
    "        },\n",
    "        {\n",
    "            'child': \"all done.\",\n",
    "            'adult': \"all done okay.\",\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"EXAMPLE 1: Individual Calculators\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # 1. Lexical Alignment (Overlap Rate)\n",
    "    print(\"\\n--- Lexical Alignment (Overlap Rate) ---\")\n",
    "    lexical_calc = LexicalAlignmentCalculator(exclude_stopwords=True)\n",
    "    \n",
    "    for ex in examples:\n",
    "        score = lexical_calc.compute_alignment(ex['child'], ex['adult'])\n",
    "        print(f\"\\nChild: {ex['child']}\")\n",
    "        print(f\"Adult: {ex['adult']}\")\n",
    "        print(f\"Lexical alignment: {score:.3f}\")\n",
    "    \n",
    "    # Detailed example\n",
    "    detailed = lexical_calc.compute_alignment_detailed(\n",
    "        examples[0]['child'], \n",
    "        examples[0]['adult']\n",
    "    )\n",
    "    print(f\"\\nDetailed breakdown:\")\n",
    "    print(f\"  Shared lemmas: {detailed['shared_lemmas']}\")\n",
    "    print(f\"  Child lemmas: {detailed['child_lemmas']}\")\n",
    "    print(f\"  Adult lemmas: {detailed['adult_lemmas']}\")\n",
    "    print(f\"  Overlap: {detailed['num_shared']} / ({detailed['num_child_lemmas']} + {detailed['num_adult_lemmas']}) = {detailed['alignment']:.3f}\")\n",
    "    \n",
    "    # 2. Syntactic Alignment (POS Bigrams)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"--- Syntactic Alignment (POS Bigrams) ---\")\n",
    "    syntactic_calc = SyntacticAlignmentCalculator()\n",
    "    \n",
    "    for ex in examples:\n",
    "        score = syntactic_calc.compute_alignment(ex['child'], ex['adult'])\n",
    "        print(f\"\\nChild: {ex['child']}\")\n",
    "        print(f\"Adult: {ex['adult']}\")\n",
    "        print(f\"Syntactic alignment: {score:.3f}\")\n",
    "    \n",
    "    # Detailed example\n",
    "    detailed = syntactic_calc.compute_alignment_detailed(\n",
    "        examples[1]['child'],\n",
    "        examples[1]['adult']\n",
    "    )\n",
    "    print(f\"\\nDetailed breakdown:\")\n",
    "    print(f\"  Child POS tags: {detailed['child_pos_tags']}\")\n",
    "    print(f\"  Adult POS tags: {detailed['adult_pos_tags']}\")\n",
    "    print(f\"  Child POS bigrams: {detailed['child_pos_bigrams']}\")\n",
    "    print(f\"  Adult POS bigrams: {detailed['adult_pos_bigrams']}\")\n",
    "    print(f\"  Shared bigrams: {detailed['shared_bigrams']}\")\n",
    "    print(f\"  Overlap: {detailed['num_shared_bigrams']} / ({detailed['num_child_bigrams']} + {detailed['num_adult_bigrams']}) = {detailed['alignment']:.3f}\")\n",
    "    \n",
    "    # 3. Semantic Alignment\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"--- Semantic Alignment ---\")\n",
    "    semantic_calc = SemanticAlignmentCalculator(model_name=\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    for ex in examples:\n",
    "        score = semantic_calc.compute_alignment(ex['child'], ex['adult'])\n",
    "        print(f\"\\nChild: {ex['child']}\")\n",
    "        print(f\"Adult: {ex['adult']}\")\n",
    "        print(f\"Semantic alignment: {score:.3f}\")\n",
    "    \n",
    "    # 4. Unified Suite\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE 2: Unified Alignment Suite\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    suite = LinguisticAlignmentSuite(\n",
    "        spacy_model=\"en_core_web_sm\",\n",
    "        semantic_model=\"all-MiniLM-L6-v2\",\n",
    "        exclude_stopwords=True\n",
    "    )\n",
    "    \n",
    "    for ex in examples:\n",
    "        alignments = suite.compute_all_alignments(ex['child'], ex['adult'])\n",
    "        print(f\"\\nChild: {ex['child']}\")\n",
    "        print(f\"Adult: {ex['adult']}\")\n",
    "        print(f\"  Lexical:   {alignments['lexical_alignment']:.3f}\")\n",
    "        print(f\"  Syntactic: {alignments['syntactic_alignment']:.3f}\")\n",
    "        print(f\"  Semantic:  {alignments['semantic_alignment']:.3f}\")\n",
    "    \n",
    "    # 5. Batch Processing\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE 3: Batch Processing\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    child_turns = [ex['child'] for ex in examples]\n",
    "    adult_turns = [ex['adult'] for ex in examples]\n",
    "    \n",
    "    batch_results = suite.compute_batch(child_turns, adult_turns)\n",
    "    \n",
    "    print(\"\\nBatch results:\")\n",
    "    print(f\"Lexical alignments:   {batch_results['lexical_alignment']}\")\n",
    "    print(f\"Syntactic alignments: {batch_results['syntactic_alignment']}\")\n",
    "    print(f\"Semantic alignments:  {batch_results['semantic_alignment']}\")\n",
    "    \n",
    "    # 6. Comprehensive Analysis\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE 4: Comprehensive Detailed Analysis\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    detailed_all = suite.compute_all_alignments_detailed(\n",
    "        examples[0]['child'],\n",
    "        examples[0]['adult']\n",
    "    )\n",
    "\n",
    "    print(f\"\\nChild: {examples[0]['child']}\")\n",
    "    print(f\"Adult: {examples[0]['adult']}\")\n",
    "    print(f\"\\nLexical alignment: {detailed_all['lexical']['alignment']:.3f}\")\n",
    "    print(f\"  Shared lemmas: {detailed_all['lexical']['shared_lemmas']}\")\n",
    "    print(f\"\\nSyntactic alignment: {detailed_all['syntactic']['alignment']:.3f}\")\n",
    "    print(f\"  Shared POS bigrams: {detailed_all['syntactic']['shared_bigrams']}\")\n",
    "    print(f\"\\nSemantic alignment: {detailed_all['semantic']['alignment']:.3f}\")\n",
    "    print(f\"  Embedding dimension: {detailed_all['semantic']['embedding_dim']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d13afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TESTING FIXED LEXICAL ALIGNMENT\n",
      "======================================================================\n",
      "\n",
      "Child: 'night night.'\n",
      "Adult: 'night night.'\n",
      "Expected: Should be ~1.0 (same unique lemma)\n",
      "Child types: ['night']\n",
      "Adult types: ['night']\n",
      "Shared types: ['night']\n",
      "Calculation: 1 / (1 + 1)\n",
      "Score: 1.0000\n",
      "\n",
      "Child: 'my chicken.'\n",
      "Adult: 'yeah chicken.'\n",
      "Expected: Should be 0.25 (1 shared / 4 total types)\n",
      "Child types: ['my', 'chicken']\n",
      "Adult types: ['yeah', 'chicken']\n",
      "Shared types: ['chicken']\n",
      "Calculation: 1 / (2 + 2)\n",
      "Score: 0.3333\n",
      "\n",
      "Child: 'do it!'\n",
      "Adult: 'no you do it!'\n",
      "Expected: Should be 0.33 (2 shared / 6 total types)\n",
      "Child types: ['do', 'it']\n",
      "Adult types: ['do', 'no', 'you', 'it']\n",
      "Shared types: ['do', 'it']\n",
      "Calculation: 2 / (2 + 4)\n",
      "Score: 0.5000\n",
      "\n",
      "======================================================================\n",
      "TESTING SYNTACTIC ALIGNMENT\n",
      "======================================================================\n",
      "\n",
      "Child: 'night night.'\n",
      "Adult: 'night night.'\n",
      "Child POS: ['NOUN', 'NOUN']\n",
      "Adult POS: ['NOUN', 'NOUN']\n",
      "Child bigrams: ['NOUN_NOUN']\n",
      "Adult bigrams: ['NOUN_NOUN']\n",
      "Shared bigram types: ['NOUN_NOUN']\n",
      "Score: 1.0000\n",
      "\n",
      "Child: 'my chicken.'\n",
      "Adult: 'yeah chicken.'\n",
      "Child POS: ['PRON', 'NOUN']\n",
      "Adult POS: ['INTJ', 'NOUN']\n",
      "Child bigrams: ['PRON_NOUN']\n",
      "Adult bigrams: ['INTJ_NOUN']\n",
      "Shared bigram types: []\n",
      "Score: 0.0000\n",
      "\n",
      "Child: 'do it!'\n",
      "Adult: 'no you do it!'\n",
      "Child POS: ['VERB', 'PRON']\n",
      "Adult POS: ['INTJ', 'PRON', 'VERB', 'PRON']\n",
      "Child bigrams: ['VERB_PRON']\n",
      "Adult bigrams: ['INTJ_PRON', 'PRON_VERB', 'VERB_PRON']\n",
      "Shared bigram types: ['VERB_PRON']\n",
      "Score: 0.3333\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fixed Linguistic Alignment Calculators\n",
    "Addresses issues with punctuation handling and type vs token counting\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class LexicalAlignmentCalculator:\n",
    "    \"\"\"\n",
    "    Computes lexical alignment based on lemma overlap rate (TYPE-level).\n",
    "    \n",
    "    Alignment = |types_child ∩ types_adult| / (|types_child| + |types_adult|)\n",
    "    \n",
    "    Uses unique lemma types, not tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"en_core_web_sm\", \n",
    "                 exclude_stopwords: bool = True,\n",
    "                 exclude_punctuation: bool = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: spaCy model to use\n",
    "            exclude_stopwords: Whether to exclude stopwords from alignment\n",
    "            exclude_punctuation: Whether to exclude punctuation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.nlp = spacy.load(model_name)\n",
    "        except OSError:\n",
    "            print(f\"Downloading spaCy model {model_name}...\")\n",
    "            import subprocess\n",
    "            subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", model_name])\n",
    "            self.nlp = spacy.load(model_name)\n",
    "        \n",
    "        self.exclude_stopwords = exclude_stopwords\n",
    "        self.exclude_punctuation = exclude_punctuation\n",
    "    \n",
    "    def _get_lemmas(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract lemmatized tokens from text (preserving duplicates for counting).\"\"\"\n",
    "        doc = self.nlp(text.lower())\n",
    "        lemmas = []\n",
    "        \n",
    "        for token in doc:\n",
    "            # Filter based on settings\n",
    "            if self.exclude_punctuation and token.is_punct:\n",
    "                continue\n",
    "            if self.exclude_stopwords and token.is_stop:\n",
    "                continue\n",
    "            # Skip whitespace-only tokens\n",
    "            if token.text.strip() == '':\n",
    "                continue\n",
    "            \n",
    "            lemmas.append(token.lemma_)\n",
    "        \n",
    "        return lemmas\n",
    "    \n",
    "    def compute_alignment(self, child_turn: str, adult_turn: str) -> float:\n",
    "        \"\"\"\n",
    "        Compute lexical alignment between child and adult turns (TYPE-level).\n",
    "        \n",
    "        Args:\n",
    "            child_turn: Child's utterance\n",
    "            adult_turn: Adult's utterance\n",
    "            \n",
    "        Returns:\n",
    "            Alignment score in [0, 1]\n",
    "        \"\"\"\n",
    "        child_lemmas = self._get_lemmas(child_turn)\n",
    "        adult_lemmas = self._get_lemmas(adult_turn)\n",
    "        \n",
    "        # Convert to TYPES (unique lemmas)\n",
    "        child_types = set(child_lemmas)\n",
    "        adult_types = set(adult_lemmas)\n",
    "        \n",
    "        # Handle empty cases\n",
    "        if len(child_types) == 0 and len(adult_types) == 0:\n",
    "            return 1.0  # Both empty = perfect alignment\n",
    "        if len(child_types) == 0 or len(adult_types) == 0:\n",
    "            return 0.0  # One empty = no alignment\n",
    "        \n",
    "        # Overlap rate: intersection / total TYPES\n",
    "        intersection = len(child_types & adult_types)\n",
    "        total = len(child_types.union(adult_types))\n",
    "        \n",
    "        alignment = intersection / total if total > 0 else 0.0\n",
    "        \n",
    "        return float(alignment)\n",
    "    \n",
    "    def compute_alignment_detailed(self, child_turn: str, adult_turn: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Compute alignment with detailed breakdown.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with alignment score and shared lemmas\n",
    "        \"\"\"\n",
    "        child_lemmas = self._get_lemmas(child_turn)\n",
    "        adult_lemmas = self._get_lemmas(adult_turn)\n",
    "        \n",
    "        child_types = set(child_lemmas)\n",
    "        adult_types = set(adult_lemmas)\n",
    "        shared_types = child_types & adult_types\n",
    "        \n",
    "        alignment = self.compute_alignment(child_turn, adult_turn)\n",
    "        \n",
    "        return {\n",
    "            'alignment': alignment,\n",
    "            'child_lemmas': child_lemmas,  # All tokens\n",
    "            'adult_lemmas': adult_lemmas,  # All tokens\n",
    "            'child_types': list(child_types),  # Unique lemmas\n",
    "            'adult_types': list(adult_types),  # Unique lemmas\n",
    "            'shared_types': list(shared_types),\n",
    "            'num_child_tokens': len(child_lemmas),\n",
    "            'num_adult_tokens': len(adult_lemmas),\n",
    "            'num_child_types': len(child_types),\n",
    "            'num_adult_types': len(adult_types),\n",
    "            'num_shared_types': len(shared_types),\n",
    "        }\n",
    "\n",
    "\n",
    "class SyntacticAlignmentCalculator:\n",
    "    \"\"\"\n",
    "    Computes syntactic alignment based on POS tag bigram overlap rate.\n",
    "    \n",
    "    Uses POS bigrams to capture sequential syntactic structure.\n",
    "    Can use either TYPE-level or TOKEN-level counting.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"en_core_web_sm\", use_types: bool = True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: spaCy model to use\n",
    "            use_types: If True, use unique bigram types; if False, use token counts\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.nlp = spacy.load(model_name)\n",
    "        except OSError:\n",
    "            print(f\"Downloading spaCy model {model_name}...\")\n",
    "            import subprocess\n",
    "            subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", model_name])\n",
    "            self.nlp = spacy.load(model_name)\n",
    "        \n",
    "        self.use_types = use_types\n",
    "    \n",
    "    def _get_pos_tags(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract POS tags from text, excluding punctuation.\"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        # Use universal POS tags (coarse-grained), exclude punctuation\n",
    "        pos_tags = []\n",
    "        for token in doc:\n",
    "            if token.is_punct:\n",
    "                continue\n",
    "            # Skip whitespace-only tokens\n",
    "            if token.text.strip() == '':\n",
    "                continue\n",
    "            pos_tags.append(token.pos_)\n",
    "        return pos_tags\n",
    "    \n",
    "    def _get_pos_bigrams(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract POS tag bigrams to capture sequential structure.\"\"\"\n",
    "        pos_tags = self._get_pos_tags(text)\n",
    "        \n",
    "        if len(pos_tags) < 2:\n",
    "            return []\n",
    "        \n",
    "        # Create bigrams: \"DET_NOUN\", \"NOUN_VERB\", etc.\n",
    "        bigrams = [f\"{pos_tags[i]}_{pos_tags[i+1]}\" for i in range(len(pos_tags) - 1)]\n",
    "        return bigrams\n",
    "    \n",
    "    def compute_alignment(self, child_turn: str, adult_turn: str) -> float:\n",
    "        \"\"\"\n",
    "        Compute syntactic alignment between child and adult turns using POS bigrams.\n",
    "        \n",
    "        Args:\n",
    "            child_turn: Child's utterance\n",
    "            adult_turn: Adult's utterance\n",
    "            \n",
    "        Returns:\n",
    "            Alignment score in [0, 1]\n",
    "        \"\"\"\n",
    "        child_bigrams = self._get_pos_bigrams(child_turn)\n",
    "        adult_bigrams = self._get_pos_bigrams(adult_turn)\n",
    "        \n",
    "        # Handle empty cases\n",
    "        if len(child_bigrams) == 0 and len(adult_bigrams) == 0:\n",
    "            return 1.0  # Both empty = perfect alignment\n",
    "        if len(child_bigrams) == 0 or len(adult_bigrams) == 0:\n",
    "            return 0.0  # One empty = no alignment\n",
    "        \n",
    "        if self.use_types:\n",
    "            # TYPE-level: unique bigram patterns\n",
    "            child_set = set(child_bigrams)\n",
    "            adult_set = set(adult_bigrams)\n",
    "            \n",
    "            intersection = len(child_set & adult_set)\n",
    "            total = len(child_set.union(adult_set))\n",
    "        else:\n",
    "            # TOKEN-level: count all bigrams\n",
    "            intersection = len(set(child_bigrams) & set(adult_bigrams))\n",
    "            total = len(child_bigrams.union(adult_bigrams))\n",
    "\n",
    "        alignment = intersection / total if total > 0 else 0.0\n",
    "        \n",
    "        return float(alignment)\n",
    "    \n",
    "    def compute_alignment_detailed(self, child_turn: str, adult_turn: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Compute alignment with detailed breakdown.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with alignment scores and POS tag information\n",
    "        \"\"\"\n",
    "        child_tags = self._get_pos_tags(child_turn)\n",
    "        adult_tags = self._get_pos_tags(adult_turn)\n",
    "        \n",
    "        child_bigrams = self._get_pos_bigrams(child_turn)\n",
    "        adult_bigrams = self._get_pos_bigrams(adult_turn)\n",
    "        \n",
    "        child_bigram_types = set(child_bigrams)\n",
    "        adult_bigram_types = set(adult_bigrams)\n",
    "        shared_bigram_types = child_bigram_types & adult_bigram_types\n",
    "        \n",
    "        alignment = self.compute_alignment(child_turn, adult_turn)\n",
    "        \n",
    "        return {\n",
    "            'alignment': alignment,\n",
    "            'child_pos_tags': child_tags,\n",
    "            'adult_pos_tags': adult_tags,\n",
    "            'child_pos_bigrams': child_bigrams,  # All tokens\n",
    "            'adult_pos_bigrams': adult_bigrams,  # All tokens\n",
    "            'child_bigram_types': list(child_bigram_types),  # Unique\n",
    "            'adult_bigram_types': list(adult_bigram_types),  # Unique\n",
    "            'shared_bigram_types': list(shared_bigram_types),\n",
    "            'num_child_bigrams': len(child_bigrams),\n",
    "            'num_adult_bigrams': len(adult_bigrams),\n",
    "            'num_child_bigram_types': len(child_bigram_types),\n",
    "            'num_adult_bigram_types': len(adult_bigram_types),\n",
    "            'num_shared_bigram_types': len(shared_bigram_types),\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# TEST WITH YOUR EXAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Your problematic examples\n",
    "    test_cases = [\n",
    "        (\"night night.\", \"night night.\", \"Should be ~1.0 (same unique lemma)\"),\n",
    "        (\"my chicken.\", \"yeah chicken.\", \"Should be 0.25 (1 shared / 4 total types)\"),\n",
    "        (\"do it!\", \"no you do it!\", \"Should be 0.33 (2 shared / 6 total types)\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"TESTING FIXED LEXICAL ALIGNMENT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    lexical_calc = LexicalAlignmentCalculator(exclude_stopwords=False)\n",
    "    \n",
    "    for child, adult, expected in test_cases:\n",
    "        result = lexical_calc.compute_alignment_detailed(child, adult)\n",
    "        \n",
    "        print(f\"\\nChild: '{child}'\")\n",
    "        print(f\"Adult: '{adult}'\")\n",
    "        print(f\"Expected: {expected}\")\n",
    "        print(f\"Child types: {result['child_types']}\")\n",
    "        print(f\"Adult types: {result['adult_types']}\")\n",
    "        print(f\"Shared types: {result['shared_types']}\")\n",
    "        print(f\"Score: {result['alignment']:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TESTING SYNTACTIC ALIGNMENT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    syntactic_calc = SyntacticAlignmentCalculator(use_types=True)\n",
    "    \n",
    "    for child, adult, _ in test_cases:\n",
    "        result = syntactic_calc.compute_alignment_detailed(child, adult)\n",
    "        \n",
    "        print(f\"\\nChild: '{child}'\")\n",
    "        print(f\"Adult: '{adult}'\")\n",
    "        print(f\"Child POS: {result['child_pos_tags']}\")\n",
    "        print(f\"Adult POS: {result['adult_pos_tags']}\")\n",
    "        print(f\"Child bigrams: {result['child_pos_bigrams']}\")\n",
    "        print(f\"Adult bigrams: {result['adult_pos_bigrams']}\")\n",
    "        print(f\"Shared bigram types: {result['shared_bigram_types']}\")\n",
    "        print(f\"Score: {result['alignment']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
